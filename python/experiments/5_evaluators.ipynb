{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. Difficulty evaluation using trajectory rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualization of the state"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4., 5.],\n",
      "        [1., 2., 3., 4., 5.]])\n",
      "0 <class 'pendulum.state.PendulumState'>\n",
      "1 <class 'pendulum.state.PendulumState'>\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGB size=800x600 at 0x24C55B22C70>",
      "image/png": "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\n"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from framework import TrajectoryRewardsEvaluator\n",
    "from pendulum import PendulumEnvironment, PendulumRenderer\n",
    "from pendulum.heuristic import *\n",
    "from shared_parameters import *\n",
    "\n",
    "env = PendulumEnvironment(*pendulum_env_args, time_scale=5, step_reward=1.0, action_reward=-0.1, death_reward=-100.0)\n",
    "renderer = PendulumRenderer(bob_radius, connector_length, enemy_radius, enemy_y)\n",
    "\n",
    "renderer.render(env.get_starting_state(), to_image=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Note for all difficulty estimator\n",
    "\n",
    "Currently, we have a small embedding space (just one dimension),\n",
    "thus it's possible to pre-evaluate it directly, and then use the\n",
    "cached difficulty evaluations.\n",
    "\n",
    "Within the bigger space it's not possible, and we will have to\n",
    "come up with some clever way of caching, where we don't store the\n",
    "evaluation for every point space, but neither perform an evaluation\n",
    "each time for each point."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Direct difficulty estimation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pendulum(angle: 0.64, angular_speed: 0.05, vertical_position: 0.00, enemies: 0.10)\n",
      "difficulty=0.653\n"
     ]
    }
   ],
   "source": [
    "oracle = HeuristicPendulumEvaluator(connector_length, max_angle, enemy_radius, bob_radius)\n",
    "state = env.get_starting_state()\n",
    "difficulty = oracle(state)\n",
    "\n",
    "print(state.to_string())\n",
    "print(f\"difficulty={difficulty.item():.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Difficulty estimation using trajectory rewards"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.0508, 0.8492, 0.8199, 0.7940, 0.2215, 0.8766, 0.9208, 0.1729, 0.2449,\n        0.1724])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills = [1.0, 0.5, 0.0]\n",
    "weights = [0.5, 0.25, 0.25]\n",
    "agents = [HeuristicPendulumActor(enemy_radius, bob_radius, connector_length, enemy_y, skill=skill) for skill in skills]\n",
    "oracle = TrajectoryRewardsEvaluator(env, agents, weights, num_evaluations=10, max_trajectory_length=20)\n",
    "\n",
    "states = torch.vstack([env.get_starting_state() for _ in range(10)])\n",
    "oracle.evaluate(states)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
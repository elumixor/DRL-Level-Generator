{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Probabilistic\n",
    "\n",
    "Here we're going to train the generator, that outputs the probability distribution\n",
    "of the $x_{enemy}$. To do that we will use the **REINFORCE** algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from typing import Union, Literal\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.core.display import display\n",
    "from numba import njit, prange\n",
    "from torch import nn\n",
    "from torch.distributions import Normal\n",
    "from torch.optim import Adam\n",
    "\n",
    "from environments import PendulumEnvJIT\n",
    "from environments.pendulum import State\n",
    "from environments.pendulum.state import size as state_size\n",
    "from evaluators import DirectEvaluator, TrajectoryRewardsEvaluator\n",
    "from evaluators.direct_actor import Actor\n",
    "from evaluators.utils import weight_skills\n",
    "from renderer import render_single_enemy\n",
    "from shared_parameters import enemy_x_min, enemy_x_max, connector_length, max_angle, enemy_radius, bob_radius, \\\n",
    "    skill_weighting, max_trajectory_length, vertical_speed, enemy_y, current_angle, \\\n",
    "    position, angular_speed\n",
    "from utils import MLP, TrainUntil"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our generator will output the mean and std of the normal distribution for the $x_{enemy}$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "Generator(\n  (base): MLP(\n    (activation): ReLU()\n    (layers): ModuleList(\n      (0): Linear(in_features=1, out_features=4, bias=True)\n      (1): Linear(in_features=4, out_features=4, bias=True)\n    )\n  )\n  (mean): Linear(in_features=4, out_features=1, bias=True)\n  (std): Linear(in_features=4, out_features=1, bias=True)\n  (activation): LeakyReLU(negative_slope=0.01)\n  (softplus): Softplus(beta=1, threshold=20)\n)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, state_size, hidden=None, activation:Union[Literal[\"relu\"], Literal[\"lrelu\"]]=\"relu\", min_std=0.01):\n",
    "        super().__init__()\n",
    "\n",
    "        if not hidden:\n",
    "            self.base = nn.Identity()\n",
    "            self.mean = nn.Linear(1, state_size)\n",
    "            self.std = nn.Linear(1, state_size)\n",
    "\n",
    "        else:\n",
    "            self.base = MLP(1, hidden[-1], hidden)\n",
    "            self.mean = nn.Linear(hidden[-1], state_size)\n",
    "            self.std = nn.Linear(hidden[-1], state_size)\n",
    "\n",
    "        self.activation = nn.ReLU() if activation == \"relu\" else nn.LeakyReLU()\n",
    "\n",
    "        assert min_std > 0\n",
    "        self.min_std = min_std\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        mean = self.mean(x)\n",
    "\n",
    "        std = self.std(x)\n",
    "        std = self.softplus(std)\n",
    "\n",
    "        return mean, std\n",
    "\n",
    "Generator(1, [4], activation=\"lrelu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can use any method of difficulty estimation to estimate the difficulty of the given levels."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "sample_size = 50\n",
    "constrain_weight = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, let's try it out with the `DirectEvaluator`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done after 10001 iteration(s). Loss: 0.500000\n"
     ]
    }
   ],
   "source": [
    "evaluator = DirectEvaluator(connector_length, max_angle, enemy_radius, bob_radius)\n",
    "\n",
    "generator = Generator(state_size=1, hidden=[4], activation=\"lrelu\", min_std=0.1)\n",
    "optim = Adam(generator.parameters(), lr=0.001)\n",
    "\n",
    "d_in = torch.linspace(0, 1, 100).unsqueeze(1)\n",
    "\n",
    "with TrainUntil(1e-4, 100, 10000, print_frequency=100, clear=True) as trainer:\n",
    "    while not trainer.done:\n",
    "\n",
    "        # Generate mean and std, create a distribution\n",
    "        mean, std = generator(d_in)\n",
    "        distribution = Normal(mean, std)\n",
    "\n",
    "        # Sample from the distribution and the log probabilities\n",
    "        x = distribution.sample([sample_size])\n",
    "        log_prob = distribution.log_prob(x)\n",
    "\n",
    "        # Transpose to [batch_size, sample_size, 1]\n",
    "        x = x.transpose(0, 1)\n",
    "        log_prob = log_prob.transpose(0, 1)\n",
    "\n",
    "        # Constrain the samples to a valid range\n",
    "        x_constrained = x.clamp(enemy_x_min, enemy_x_max)\n",
    "\n",
    "        # Compute basic loss of the clamped samples\n",
    "        # d_out will just be the distance from the target\n",
    "        # this is simply how we chose it to be for this case\n",
    "        d_out = evaluator.evaluate(x_constrained)\n",
    "\n",
    "        # Difference in the difficulties we will minimize\n",
    "        # d_in shape [batch_size, 1] -> [batch_size, 1, 1] -> [batch_size, sample_size, 1]\n",
    "        difference = (d_out - d_in.unsqueeze(1)).abs()\n",
    "\n",
    "        # Compute the clamp penalty\n",
    "        clamp_penalty = (x_constrained - x).abs()\n",
    "\n",
    "        # Weight everything together\n",
    "        # - minimize the difference in d_in and d_out\n",
    "        # - minimize the difference between x and x_constrained\n",
    "        loss = ((difference + constrain_weight * clamp_penalty) * log_prob).mean()\n",
    "\n",
    "        # Total weighted loss\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        trainer.loss = (evaluator.evaluate(mean) - d_in).abs().mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGB size=200x150 at 0x1776E6003A0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAACWCAIAAAAUvlBOAAACpElEQVR4nO3cwW3iUABFUWc0xVANZaSolOFqUPb0MQukCGUGYuDfMHbOWXmD9BdXj78wvByPx4kFdrvd4XB49ilW49ezD8A2CYuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLxMvxeHz2GVZgv99/PM/z/MSTrIXFIiEsEsIiIaxF5nl+f393u1pOWDc7v8hzibBuY7QWEtbN5nk2Wl8SFglh3cNofUlY99PWFcK6k1v8dcJ6iNG6RFj3M1pXCOshbvGXCIuEsB5ltP5JWGNo6xNhDeAW/zdhDWO0zglrDKP1ibCGcYs/JywSwhrJaH0Q1njamoQ1nFv8ibASRktY4xmtSVgRt3hhhX5yW7+ffYDNujRab29vH8+vr6/feKJvJazWfr+f5/k8pnMbjsz/Yy212+0Oh8Otn7qU1CWbycsdK3RrVfd95P8krMrdiWyjLWElHoxjA20Ja7whWay9LWENNjCIVbclLBLCGmn4xqx3tIRFQljDROuy0tESFglhkRAWCWGREBYJYZEQFglhDRO9o7fSV/+ERUJYJIQ10vCvrZV+D07CIiKswQZuzHrnahJWYUgQq65qElbkwSzWXtUkrM7dcWygqslP7FOnRJa/qbeNpE6ElVuS15aSOhHWN9leOte5Y5EQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWiT+0noXl0/XkjwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0.0"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGB size=200x150 at 0x1776E600E50>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAACWCAIAAAAUvlBOAAACpElEQVR4nO3cwW3iUABFUWc0xVANZaSolOFqUPb0MQukCGUGYuDfMHbOWXmD9BdXj78wvByPx4kFdrvd4XB49ilW49ezD8A2CYuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLxMvxeHz2GVZgv99/PM/z/MSTrIXFIiEsEsIiIaxF5nl+f393u1pOWDc7v8hzibBuY7QWEtbN5nk2Wl8SFglh3cNofUlY99PWFcK6k1v8dcJ6iNG6RFj3M1pXCOshbvGXCIuEsB5ltP5JWGNo6xNhDeAW/zdhDWO0zglrDKP1ibCGcYs/JywSwhrJaH0Q1njamoQ1nFv8ibASRktY4xmtSVgRt3hhhX5yW7+ffYDNujRab29vH8+vr6/feKJvJazWfr+f5/k8pnMbjsz/Yy212+0Oh8Otn7qU1CWbycsdK3RrVfd95P8krMrdiWyjLWElHoxjA20Ja7whWay9LWENNjCIVbclLBLCGmn4xqx3tIRFQljDROuy0tESFglhkRAWCWGREBYJYZEQFglhDRO9o7fSV/+ERUJYJIQ10vCvrZV+D07CIiKswQZuzHrnahJWYUgQq65qElbkwSzWXtUkrM7dcWygqslP7FOnRJa/qbeNpE6ElVuS15aSOhHWN9leOte5Y5EQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWiT+0noXl0/XkjwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0.1111111119389534"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGB size=200x150 at 0x177701DF040>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAACWCAIAAAAUvlBOAAACpElEQVR4nO3cwW3iUABFUWc0xVANZaSolOFqUPb0MQukCGUGYuDfMHbOWXmD9BdXj78wvByPx4kFdrvd4XB49ilW49ezD8A2CYuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLxMvxeHz2GVZgv99/PM/z/MSTrIXFIiEsEsIiIaxF5nl+f393u1pOWDc7v8hzibBuY7QWEtbN5nk2Wl8SFglh3cNofUlY99PWFcK6k1v8dcJ6iNG6RFj3M1pXCOshbvGXCIuEsB5ltP5JWGNo6xNhDeAW/zdhDWO0zglrDKP1ibCGcYs/JywSwhrJaH0Q1njamoQ1nFv8ibASRktY4xmtSVgRt3hhhX5yW7+ffYDNujRab29vH8+vr6/feKJvJazWfr+f5/k8pnMbjsz/Yy212+0Oh8Otn7qU1CWbycsdK3RrVfd95P8krMrdiWyjLWElHoxjA20Ja7whWay9LWENNjCIVbclLBLCGmn4xqx3tIRFQljDROuy0tESFglhkRAWCWGREBYJYZEQFglhDRO9o7fSV/+ERUJYJIQ10vCvrZV+D07CIiKswQZuzHrnahJWYUgQq65qElbkwSzWXtUkrM7dcWygqslP7FOnRJa/qbeNpE6ElVuS15aSOhHWN9leOte5Y5EQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWiT+0noXl0/XkjwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0.2222222238779068"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGB size=200x150 at 0x177701C8E80>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAACWCAIAAAAUvlBOAAACpElEQVR4nO3cwW3iUABFUWc0xVANZaSolOFqUPb0MQukCGUGYuDfMHbOWXmD9BdXj78wvByPx4kFdrvd4XB49ilW49ezD8A2CYuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLxMvxeHz2GVZgv99/PM/z/MSTrIXFIiEsEsIiIaxF5nl+f393u1pOWDc7v8hzibBuY7QWEtbN5nk2Wl8SFglh3cNofUlY99PWFcK6k1v8dcJ6iNG6RFj3M1pXCOshbvGXCIuEsB5ltP5JWGNo6xNhDeAW/zdhDWO0zglrDKP1ibCGcYs/JywSwhrJaH0Q1njamoQ1nFv8ibASRktY4xmtSVgRt3hhhX5yW7+ffYDNujRab29vH8+vr6/feKJvJazWfr+f5/k8pnMbjsz/Yy212+0Oh8Otn7qU1CWbycsdK3RrVfd95P8krMrdiWyjLWElHoxjA20Ja7whWay9LWENNjCIVbclLBLCGmn4xqx3tIRFQljDROuy0tESFglhkRAWCWGREBYJYZEQFglhDRO9o7fSV/+ERUJYJIQ10vCvrZV+D07CIiKswQZuzHrnahJWYUgQq65qElbkwSzWXtUkrM7dcWygqslP7FOnRJa/qbeNpE6ElVuS15aSOhHWN9leOte5Y5EQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWiT+0noXl0/XkjwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0.3333333432674408"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGB size=200x150 at 0x1776E6009D0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAACWCAIAAAAUvlBOAAACpElEQVR4nO3cwW3iUABFUWc0xVANZaSolOFqUPb0MQukCGUGYuDfMHbOWXmD9BdXj78wvByPx4kFdrvd4XB49ilW49ezD8A2CYuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLxMvxeHz2GVZgv99/PM/z/MSTrIXFIiEsEsIiIaxF5nl+f393u1pOWDc7v8hzibBuY7QWEtbN5nk2Wl8SFglh3cNofUlY99PWFcK6k1v8dcJ6iNG6RFj3M1pXCOshbvGXCIuEsB5ltP5JWGNo6xNhDeAW/zdhDWO0zglrDKP1ibCGcYs/JywSwhrJaH0Q1njamoQ1nFv8ibASRktY4xmtSVgRt3hhhX5yW7+ffYDNujRab29vH8+vr6/feKJvJazWfr+f5/k8pnMbjsz/Yy212+0Oh8Otn7qU1CWbycsdK3RrVfd95P8krMrdiWyjLWElHoxjA20Ja7whWay9LWENNjCIVbclLBLCGmn4xqx3tIRFQljDROuy0tESFglhkRAWCWGREBYJYZEQFglhDRO9o7fSV/+ERUJYJIQ10vCvrZV+D07CIiKswQZuzHrnahJWYUgQq65qElbkwSzWXtUkrM7dcWygqslP7FOnRJa/qbeNpE6ElVuS15aSOhHWN9leOte5Y5EQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWiT+0noXl0/XkjwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0.4444444477558136"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGB size=200x150 at 0x177701EFF10>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAACWCAIAAAAUvlBOAAACpElEQVR4nO3cwW3iUABFUWc0xVANZaSolOFqUPb0MQukCGUGYuDfMHbOWXmD9BdXj78wvByPx4kFdrvd4XB49ilW49ezD8A2CYuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLxMvxeHz2GVZgv99/PM/z/MSTrIXFIiEsEsIiIaxF5nl+f393u1pOWDc7v8hzibBuY7QWEtbN5nk2Wl8SFglh3cNofUlY99PWFcK6k1v8dcJ6iNG6RFj3M1pXCOshbvGXCIuEsB5ltP5JWGNo6xNhDeAW/zdhDWO0zglrDKP1ibCGcYs/JywSwhrJaH0Q1njamoQ1nFv8ibASRktY4xmtSVgRt3hhhX5yW7+ffYDNujRab29vH8+vr6/feKJvJazWfr+f5/k8pnMbjsz/Yy212+0Oh8Otn7qU1CWbycsdK3RrVfd95P8krMrdiWyjLWElHoxjA20Ja7whWay9LWENNjCIVbclLBLCGmn4xqx3tIRFQljDROuy0tESFglhkRAWCWGREBYJYZEQFglhDRO9o7fSV/+ERUJYJIQ10vCvrZV+D07CIiKswQZuzHrnahJWYUgQq65qElbkwSzWXtUkrM7dcWygqslP7FOnRJa/qbeNpE6ElVuS15aSOhHWN9leOte5Y5EQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWiT+0noXl0/XkjwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0.5555555820465088"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGB size=200x150 at 0x1777017DC10>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAACWCAIAAAAUvlBOAAACpElEQVR4nO3cwW3iUABFUWc0xVANZaSolOFqUPb0MQukCGUGYuDfMHbOWXmD9BdXj78wvByPx4kFdrvd4XB49ilW49ezD8A2CYuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLxMvxeHz2GVZgv99/PM/z/MSTrIXFIiEsEsIiIaxF5nl+f393u1pOWDc7v8hzibBuY7QWEtbN5nk2Wl8SFglh3cNofUlY99PWFcK6k1v8dcJ6iNG6RFj3M1pXCOshbvGXCIuEsB5ltP5JWGNo6xNhDeAW/zdhDWO0zglrDKP1ibCGcYs/JywSwhrJaH0Q1njamoQ1nFv8ibASRktY4xmtSVgRt3hhhX5yW7+ffYDNujRab29vH8+vr6/feKJvJazWfr+f5/k8pnMbjsz/Yy212+0Oh8Otn7qU1CWbycsdK3RrVfd95P8krMrdiWyjLWElHoxjA20Ja7whWay9LWENNjCIVbclLBLCGmn4xqx3tIRFQljDROuy0tESFglhkRAWCWGREBYJYZEQFglhDRO9o7fSV/+ERUJYJIQ10vCvrZV+D07CIiKswQZuzHrnahJWYUgQq65qElbkwSzWXtUkrM7dcWygqslP7FOnRJa/qbeNpE6ElVuS15aSOhHWN9leOte5Y5EQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWiT+0noXl0/XkjwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0.6666666269302368"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGB size=200x150 at 0x177701DFA60>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAACWCAIAAAAUvlBOAAACpElEQVR4nO3cwW3iUABFUWc0xVANZaSolOFqUPb0MQukCGUGYuDfMHbOWXmD9BdXj78wvByPx4kFdrvd4XB49ilW49ezD8A2CYuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLxMvxeHz2GVZgv99/PM/z/MSTrIXFIiEsEsIiIaxF5nl+f393u1pOWDc7v8hzibBuY7QWEtbN5nk2Wl8SFglh3cNofUlY99PWFcK6k1v8dcJ6iNG6RFj3M1pXCOshbvGXCIuEsB5ltP5JWGNo6xNhDeAW/zdhDWO0zglrDKP1ibCGcYs/JywSwhrJaH0Q1njamoQ1nFv8ibASRktY4xmtSVgRt3hhhX5yW7+ffYDNujRab29vH8+vr6/feKJvJazWfr+f5/k8pnMbjsz/Yy212+0Oh8Otn7qU1CWbycsdK3RrVfd95P8krMrdiWyjLWElHoxjA20Ja7whWay9LWENNjCIVbclLBLCGmn4xqx3tIRFQljDROuy0tESFglhkRAWCWGREBYJYZEQFglhDRO9o7fSV/+ERUJYJIQ10vCvrZV+D07CIiKswQZuzHrnahJWYUgQq65qElbkwSzWXtUkrM7dcWygqslP7FOnRJa/qbeNpE6ElVuS15aSOhHWN9leOte5Y5EQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWiT+0noXl0/XkjwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0.7777777910232544"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGB size=200x150 at 0x1776E2E8670>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAACWCAIAAAAUvlBOAAACpElEQVR4nO3cwW3iUABFUWc0xVANZaSolOFqUPb0MQukCGUGYuDfMHbOWXmD9BdXj78wvByPx4kFdrvd4XB49ilW49ezD8A2CYuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLxMvxeHz2GVZgv99/PM/z/MSTrIXFIiEsEsIiIaxF5nl+f393u1pOWDc7v8hzibBuY7QWEtbN5nk2Wl8SFglh3cNofUlY99PWFcK6k1v8dcJ6iNG6RFj3M1pXCOshbvGXCIuEsB5ltP5JWGNo6xNhDeAW/zdhDWO0zglrDKP1ibCGcYs/JywSwhrJaH0Q1njamoQ1nFv8ibASRktY4xmtSVgRt3hhhX5yW7+ffYDNujRab29vH8+vr6/feKJvJazWfr+f5/k8pnMbjsz/Yy212+0Oh8Otn7qU1CWbycsdK3RrVfd95P8krMrdiWyjLWElHoxjA20Ja7whWay9LWENNjCIVbclLBLCGmn4xqx3tIRFQljDROuy0tESFglhkRAWCWGREBYJYZEQFglhDRO9o7fSV/+ERUJYJIQ10vCvrZV+D07CIiKswQZuzHrnahJWYUgQq65qElbkwSzWXtUkrM7dcWygqslP7FOnRJa/qbeNpE6ElVuS15aSOhHWN9leOte5Y5EQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWiT+0noXl0/XkjwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0.8888888955116272"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGB size=200x150 at 0x1776E1D07C0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAACWCAIAAAAUvlBOAAACpElEQVR4nO3cwW3iUABFUWc0xVANZaSolOFqUPb0MQukCGUGYuDfMHbOWXmD9BdXj78wvByPx4kFdrvd4XB49ilW49ezD8A2CYuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLxMvxeHz2GVZgv99/PM/z/MSTrIXFIiEsEsIiIaxF5nl+f393u1pOWDc7v8hzibBuY7QWEtbN5nk2Wl8SFglh3cNofUlY99PWFcK6k1v8dcJ6iNG6RFj3M1pXCOshbvGXCIuEsB5ltP5JWGNo6xNhDeAW/zdhDWO0zglrDKP1ibCGcYs/JywSwhrJaH0Q1njamoQ1nFv8ibASRktY4xmtSVgRt3hhhX5yW7+ffYDNujRab29vH8+vr6/feKJvJazWfr+f5/k8pnMbjsz/Yy212+0Oh8Otn7qU1CWbycsdK3RrVfd95P8krMrdiWyjLWElHoxjA20Ja7whWay9LWENNjCIVbclLBLCGmn4xqx3tIRFQljDROuy0tESFglhkRAWCWGREBYJYZEQFglhDRO9o7fSV/+ERUJYJIQ10vCvrZV+D07CIiKswQZuzHrnahJWYUgQq65qElbkwSzWXtUkrM7dcWygqslP7FOnRJa/qbeNpE6ElVuS15aSOhHWN9leOte5Y5EQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWiT+0noXl0/XkjwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "1.0"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_in = torch.linspace(0, 1, 10).unsqueeze(1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    means, stds = generator(d_in)\n",
    "\n",
    "enemy_xs = Normal(means, stds).sample([1]).transpose(0, 1)\n",
    "\n",
    "for enemy_x, d in zip(enemy_xs, d_in):\n",
    "    display(render_single_enemy(enemy_x.item(), 0.25))\n",
    "    display(d.item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's use `TrajectoryRewardsEvaluator`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2243, loss: 0.4177600\n"
     ]
    }
   ],
   "source": [
    "env = PendulumEnvJIT()\n",
    "skills = torch.linspace(0, 1, 10)\n",
    "actors = [Actor(skill) for skill in skills.numpy()]\n",
    "actors_weights = weight_skills(skills, skill_weighting.mean, skill_weighting.std, skill_weighting.skew)\n",
    "\n",
    "generator = Generator(state_size=1, hidden=[4], activation=\"lrelu\", min_std=0.1)\n",
    "evaluator = TrajectoryRewardsEvaluator(env, actors, actors_weights, 10, max_trajectory_length)\n",
    "\n",
    "d_in = torch.linspace(0, 1, 100).unsqueeze(1)\n",
    "\n",
    "@njit(parallel=True)\n",
    "def transform(x):\n",
    "    states = np.zeros((x.shape[0], x.shape[1], state_size), dtype=np.float32)\n",
    "    for i in prange(x.shape[0]):\n",
    "        for j in prange(x.shape[1]):\n",
    "            states[i][j] = State(bob_radius, max_angle, connector_length, vertical_speed, x[i][j][0], enemy_y,\n",
    "                                 enemy_radius, current_angle, position, angular_speed)\n",
    "    return states\n",
    "\n",
    "with TrainUntil(1e-4, 100, 10000, print_frequency=1, clear=True) as trainer:\n",
    "    while not trainer.done:\n",
    "\n",
    "        # Generate mean and std, create a distribution\n",
    "        mean, std = generator(d_in)\n",
    "        distribution = Normal(mean, std)\n",
    "\n",
    "        # Sample from the distribution and the log probabilities\n",
    "        x = distribution.sample([sample_size])\n",
    "        log_prob = distribution.log_prob(x)\n",
    "\n",
    "        # Transpose to [batch_size, sample_size, 1]\n",
    "        x = x.transpose(0, 1)\n",
    "        log_prob = log_prob.transpose(0, 1)\n",
    "\n",
    "        # Constrain the samples to a valid range\n",
    "        x_constrained = x.clamp(enemy_x_min, enemy_x_max)\n",
    "\n",
    "        # Compute basic loss of the clamped samples\n",
    "        # d_out will just be the distance from the target\n",
    "        # this is simply how we chose it to be for this case\n",
    "        states = transform(x.numpy().astype(np.float32))\n",
    "        d_out = torch.from_numpy(evaluator.evaluate(states)).type(torch.float32)\n",
    "\n",
    "        # Difference in the difficulties we will minimize\n",
    "        # d_in shape [batch_size, 1] -> [batch_size, 1, 1] -> [batch_size, sample_size, 1]\n",
    "        difference = (d_out - d_in.unsqueeze(1)).abs()\n",
    "\n",
    "        # Compute the clamp penalty\n",
    "        clamp_penalty = (x_constrained - x).abs()\n",
    "\n",
    "        # Weight everything together\n",
    "        # - minimize the difference in d_in and d_out\n",
    "        # - minimize the difference between x and x_constrained\n",
    "        loss = ((difference + constrain_weight * clamp_penalty) * log_prob).mean()\n",
    "\n",
    "        # Total weighted loss\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        trainer.loss = difference.mean()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d_in = torch.linspace(0, 1, 10).unsqueeze(1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    means, stds = generator(d_in)\n",
    "\n",
    "enemy_xs = Normal(means, stds).sample([1]).transpose(0, 1)\n",
    "\n",
    "for enemy_x, d in zip(enemy_xs, d_in):\n",
    "    display(render_single_enemy(enemy_x.item(), 0.25))\n",
    "    display(d.item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}